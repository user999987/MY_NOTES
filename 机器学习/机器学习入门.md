(色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂:稍蜷;敲声=沉 闷)， (色泽=浅自;根蒂t硬挺;敲声=清脆) 每对括号内是一条记录\
data set: 上面这组记录的集合 \
instance/sample: 每个记录关于一个事件或者对象的描述\
feature/attribute: 事件或对象某方面的表现或性质\
attribute value: \
attribute/sample/input space: \
feature vector: "色泽" "根蒂" "敲声"作为三个坐标轴，则它们张成 一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位 置.空间中的每个点对应一个坐标向量\
D = $\{x_1,x_2,...x_m\}$: m 个 instance 的 data set \
$x_i = (x_{i1};x_{i2};...x_{id})$ : 每个 示例由 d 个属性描述(例如上面的西瓜数据使用了 3 个属性)  $x_i$是 d 维 样本空间 X 中的一个 vector\
example: instance with label\
classification: 预测离散值\
regression: 预测连续值\
supervised learning: data set with label\
unsupervised learning: data set without label\
induction: 特殊到一般的"泛化" (generalization)过程，即从具体的事实归结出一般性规 律 \
deduction: 一般到特殊的"特化" (specializatio叫过程，即从基础原理推演
出具体状况.例如，在数学公理系镜中，基于一组公理和推理规则推导出与之 相洽的定理\
hypothesis space: 色泽 根蒂 敲声 的各种搭配 \
version space: 现实问题中我们常面临很大的假设空间?但学习过程是基于 有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与 训练集一致的"假设集合"\
```
编号色泽根蒂敲声好瓜
1 青绿蜷缩浊响 是 
2 乌黑蜷缩浊响 是 
3 青绿硬挺清脆 否 
4 乌黑稍蜷沉闷 否
```
inductive bias: (色泽口青绿; 根蒂=蜷缩;敲声=沉闷)这个新收来的瓜，如果我们采用的是"好瓜村(色 泽= *)八(根蒂=蜷缩)八(敲声=*)"，那么将会把新瓜判断为好瓜，而如果采 用了另外两个假设，则判断的结果将不是好瓜. 对于一个具体的学习算法而言?它必须要产生一个模型.这时，学习算 法本身的"偏好"就会起到关键的作用.例如，若我们的算法喜欢"尽可能特 殊"的模型，则它会选择"好瓜件(色泽= *)八(根蒂=蜷缩)八(敲声=浊晌)" ; 但若我们的算法喜欢"尽可能一般"的模型，并且由于某种原因它更"相信" 根蒂，则它会选择"好瓜件(色泽= *) ^(根蒂=蜷缩)八(敲声= *)" .机器学习 算法在学习过程中对某种类型假设的偏好\
任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看 似在训练集上"等效"的假设所迷惑，而无法产生确定的学习结果. 什么意思呢, 就是瓜"(色泽=青绿;根蒂口蜷缩;敲声=沉
闷)" ，学得模型时而告诉我们它是好的、时而告诉我们它是不好的，这样的学 习没有意义.\
Occam's razor: 一种一般性的原则来引导算法确立 "正确的"偏好 自然科学 研究中最基本的原则，即"若有多个假设与观察一致，则选最简单的那个 具体例子就是 当用上表画图的时候可以有非常多条曲线满足 此时选择最平滑的那条 即最简单的那个