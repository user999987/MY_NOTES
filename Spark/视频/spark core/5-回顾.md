1. RDD lineage 理解
* A: 描述 两个相关RDD之间的关联 用来恢复数据 用在任务切分

2. Spark如何进行任务切分
* A: 提交 application (sc), application中会有很多transformation 和 action 算子, 一个action 对应一个 job 一个 job 根据 wide dependency 划分 stage (shuffle让spark可以迭代计算map/reduce 比hadoop快) 预估 切片数 起相对应的 核数

3. cache和checkPoint区别和联系
* A: 缓存RDD 防止重复计算  cache默认内存, 不切断lineage 会被重复使用但不是很大  checkPoint默认磁盘, 必须放在第一个 action之前, action 发生时 切断lineage application退出 checkPoint也不会丢失 运算时间很长 或 运算量太大 computing chaine过长活着依赖很多其他 RDD 的RDD

4. 自定义分区 可否按 Value分区
* A: partitionBy(new HashPartitioner(100))  不可 override def getPartition(key: Any): Int = ??? 只有key传了进去

5. Spark读取HDFS文件默认的切片机制
* A: 遍历所有文件得到 totalSize, goalSize= totalSize/2 (2是默认最小并行度或者分区数), 
splitsize= max(1, min( goalSize, blockSize )) #注意单位是bytes blockSize 32Mb就是33554432, totalSize/splitSize 得到分区数 从而得到需要多少个 Core

6. Broadcast
* A: 发送给每个executor bc=sc.broadcast(val) bc.value

7. Custom accumulator
* A: 
```
>>> from pyspark.accumulators import AccumulatorParam
>>> class VectorAccumulatorParam(AccumulatorParam):
...     def zero(self, value):
...         return [0.0] * len(value)
...     def addInPlace(self, val1, val2):
...         for i in xrange(len(val1)):
...              val1[i] += val2[i]
...         return val1
>>> va = sc.accumulator([1.0, 2.0, 3.0], VectorAccumulatorParam())
```